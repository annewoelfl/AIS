{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "Logistic Regression is chosen as the baseline model due to its simplicity, interpretability, and efficiency for binary or multi-class classification tasks. As we are predicting the categorical variable Navigational Status, Logistic Regression provides a solid starting point to establish a baseline performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "The features selected are based on their relevance to predicting Navigational Status. These include:\n",
    "- Latitude and Longitude: Represent vessel position.\n",
    "- Speed over Ground (SOG): Vessel speed, which varies significantly across statuses.\n",
    "- Course over Ground (COG): Direction of the vessel.\n",
    "- Heading: Indicates the vessel's orientation.\n",
    "\n",
    "The target variable is Navigational Status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement your baseline model here.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the folder containing 15-minute set files\n",
    "data_folder = './time_intervals'\n",
    "\n",
    "# Initialize an empty DataFrame to combine data from all files\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure the required columns exist\n",
    "        required_columns = ['Latitude', 'Longitude', 'SOG', 'COG', 'Heading', 'Navigational status']\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Skipping {file}, missing required columns.\")\n",
    "\n",
    "# Feature selection\n",
    "features = ['Latitude', 'Longitude', 'SOG', 'COG', 'Heading']\n",
    "target = 'Navigational status'\n",
    "\n",
    "# Drop rows with missing values in the selected columns\n",
    "all_data = all_data.dropna(subset=features + [target])\n",
    "\n",
    "# Encode the target variable (categorical to numeric)\n",
    "all_data[target] = all_data[target].astype('category').cat.codes\n",
    "\n",
    "# Define feature matrix (X) and target vector (y)\n",
    "X = all_data[features]\n",
    "y = all_data[target]\n",
    "\n",
    "# Split the dataset into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation\n",
    "\n",
    "To evaluate the baseline model:\n",
    "\n",
    "- Accuracy: Proportion of correct predictions out of all predictions.\n",
    "- Classification Report: Includes precision, recall, and F1-score for each class, providing detailed insights into model performance.\n",
    "- Confusion Matrix: Displays actual vs. predicted values to analyze performance for each class.\n",
    "\n",
    "Example Output:\n",
    "\n",
    "- Accuracy: Indicates the overall performance.\n",
    "- Confusion Matrix: Highlights areas where the model misclassified.\n",
    "- Classification Report: Shows per-class performance metrics, aiding in identifying underperforming categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Baseline Model Accuracy:\", accuracy)\n",
    "\n",
    "# Generate and display a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=all_data[target].cat.categories, \n",
    "            yticklabels=all_data[target].cat.categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
